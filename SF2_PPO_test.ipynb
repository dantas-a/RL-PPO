{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "882b16db-f9f7-43ac-8667-859a36bb21f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permet de jouer au jeu\n",
    "import retro\n",
    "# Permet de ralentir la vitesse \n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00358d8f",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fcc1f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import Env\n",
    "from gym.spaces import MultiBinary, Box\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49926cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environnement Customisé\n",
    "class StreetFighter(Env) : \n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        # A fixer inférieure à 200\n",
    "        self.taille_reduite = 84\n",
    "        # Specification de l'espace des actions et de l'espace d'observation\n",
    "        # low = 0, high = 255 : couleur pixels par défaut\n",
    "        # shape : shape de la sortie par défaut (hauteur, largeur, Gris)\n",
    "        self.observation_space = Box(low=0,high=255,shape=(self.taille_reduite,self.taille_reduite,1),dtype=np.uint8)\n",
    "        # action_space = MultiBinary(12) : 12 touches possibles et combinables pour faire des coups spéciaux\n",
    "        self.action_space = MultiBinary(12)\n",
    "        # Lancer une instance du jeu et ne permet que les combinaisons valides de boutons\n",
    "        self.game = retro.make(game='StreetFighterIISpecialChampionEdition-Genesis', use_restricted_actions = retro.Actions.FILTERED)\n",
    "    \n",
    "    def step(self,action):\n",
    "        # Faire une étape \n",
    "        observation, reward, done, info = self.game.step(action)\n",
    "        observation = self.preprocess(observation)\n",
    "        \n",
    "        # Fonction de récompense\n",
    "        reward = info['score'] - self.score\n",
    "        self.score = info['score']\n",
    "        \n",
    "        return observation, reward, done, info\n",
    "    \n",
    "    def render(self,*args,**kwargs):\n",
    "        self.game.render()\n",
    "    \n",
    "    def reset(self):\n",
    "        # Remet le jeu à zéro\n",
    "        observation = self.game.reset()\n",
    "        # Preprocess l'image obtenue\n",
    "        observation = self.preprocess(observation)\n",
    "        # Cette variable va permettre de stocker la récompense obtenue pour la partie\n",
    "        self.score = 0\n",
    "        return observation\n",
    "    \n",
    "    def preprocess(self,observation):\n",
    "        # Transformation de l'image RGB en nuance de gris => Entraînement plus rapide\n",
    "        image_gris = cv2.cvtColor(observation,cv2.COLOR_RGB2GRAY)\n",
    "        # Modifier la taille de l'image => Entraînement plus rapide\n",
    "        image_retaillee = cv2.resize(image_gris,(self.taille_reduite,self.taille_reduite), interpolation = cv2.INTER_CUBIC)\n",
    "        # Specificité pour stable_baselines\n",
    "        image_retaillee_gris_finale = np.reshape(image_retaillee,(self.taille_reduite,self.taille_reduite,1))\n",
    "        return image_retaillee_gris_finale\n",
    "    \n",
    "    def close(self):\n",
    "        self.game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a08b55f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexandre/INSA/GM5/T2/PBIA/PBIA_Env/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "188274ff-6b20-4446-93e8-321eddc02b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = './logs/'\n",
    "OPT_DIR = './opt/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf819e13-c086-46cd-ae06-66cb6687adea",
   "metadata": {},
   "source": [
    "## Préparation de l'environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00eec3b5-b064-4863-a744-69ca4394b95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crée un environnement\n",
    "env = StreetFighter()\n",
    "# Permet d'extraire la recompense moyenne et la longueur moyenne d'un episode\n",
    "env = Monitor(env,LOG_DIR)\n",
    "#Nécessaire pour Stable Baselines\n",
    "env = DummyVecEnv([lambda: env])\n",
    "#Empile 4 images consécutives pour donner la perception de mouvement\n",
    "env = VecFrameStack(env, 4, channels_order='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae7a32b2-8371-444c-b00e-574e9ca049fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiBinary(12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cd6d156-9381-45be-8de0-d6274d2ee341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([[[0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  ...\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]]\n",
       "\n",
       " [[0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  ...\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]]\n",
       "\n",
       " [[0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  ...\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]]\n",
       "\n",
       " ...\n",
       "\n",
       " [[0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  ...\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]]\n",
       "\n",
       " [[0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  ...\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]]\n",
       "\n",
       " [[0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  ...\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]]], [[[255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  ...\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]]\n",
       "\n",
       " [[255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  ...\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]]\n",
       "\n",
       " [[255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  ...\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]]\n",
       "\n",
       " ...\n",
       "\n",
       " [[255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  ...\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]]\n",
       "\n",
       " [[255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  ...\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]]\n",
       "\n",
       " [[255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  ...\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]]], (84, 84, 4), uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890e056a-980d-44c0-bd12-7a79f4358a79",
   "metadata": {},
   "source": [
    "## Test du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a026821-3941-4532-861f-7998d5d1ad9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = './save/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f55067c-b5d4-4568-9481-8fab23e678f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(os.path.join(SAVE_DIR,'sf2_best_save_ppo_84x84'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "418799cb-3af8-4e31-990c-8da87ea05655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActorCriticCnnPolicy(\n",
       "  (features_extractor): NatureCNN(\n",
       "    (cnn): Sequential(\n",
       "      (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (5): ReLU()\n",
       "      (6): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=3136, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (mlp_extractor): MlpExtractor(\n",
       "    (shared_net): Sequential()\n",
       "    (policy_net): Sequential()\n",
       "    (value_net): Sequential()\n",
       "  )\n",
       "  (action_net): Linear(in_features=512, out_features=12, bias=True)\n",
       "  (value_net): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901c93a9-7497-4a04-869f-52e0351534a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remettre le jeu à zéro\n",
    "obs = env.reset()\n",
    "# Partie non terminée\n",
    "done = False\n",
    "# Une partie\n",
    "for game in range(1): \n",
    "    while not done: \n",
    "        if done: \n",
    "            obs = env.reset()\n",
    "        env.render()\n",
    "        # Modèle choisit \n",
    "        action = model.predict(obs)[0]\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8fb438-3241-4803-9988-46380ba4ae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PBIA_Env",
   "language": "python",
   "name": "pbia_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
